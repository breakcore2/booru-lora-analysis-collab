{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXv43wDsTDUK"
   },
   "source": [
    "# Booru Data Analysis\n",
    "This notebook will analyze good parameters to use when downloading images from boorus to create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTFftMDzULhb"
   },
   "source": [
    "## Instal dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4lmRtryTWwD",
    "outputId": "3b3f2b90-7db9-4413-8d83-e7152b8f1202"
   },
   "outputs": [],
   "source": [
    "pip install pybooru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU1NZvMmUYHS"
   },
   "source": [
    "## Get Data\n",
    "Here we will make multie queries to booru and get back all the metadata related to images relating to the tags we are searching through. This is the data we will be analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtPM8TsMUjak",
    "outputId": "806d1dbb-225b-40e7-92ad-4cb72406488a"
   },
   "outputs": [],
   "source": [
    "from pybooru import Danbooru\n",
    "\n",
    "client = Danbooru('danbooru')\n",
    "tags = \"amiya_(arknights)  -rating:explicit -rating:questionable\" #@param {'type':'string'}\n",
    "metadata = []\n",
    "page = 1\n",
    "limit = 100\n",
    "while True:\n",
    "  posts = client.post_list(limit=limit, tags=tags, page=page)\n",
    "  print(posts)\n",
    "  if len(posts) == 0:\n",
    "      print(f\"On Page {page} for tags {tags}. Found no posts. Ending.\")\n",
    "      break # we have reached the last page since there are no results\n",
    "  else:\n",
    "      metadata.extend(posts)\n",
    "      page += 1\n",
    "\n",
    "print(f\"Data collection for tags=\\\"{tags}\\\" completed. Found {len(metadata)} results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ksJpglOn1I2"
   },
   "source": [
    "## Filtering data\n",
    "Downloading the metadata early might have taken some time so we don't want to have to redownload everything as we decide to filter our dataset down by pruning for unwanted tags. We will make a copy of our metadata and work on that instead.\n",
    "We will filter it by\n",
    "1. removing posts that contain unwanted tags\n",
    "2. remove posts that don't meet a minimum score\n",
    "3. remove posts that are not parents, if desired. Useful because children posts tend to be very similar to parent posts and are often edits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCd0TpVvn0sy",
    "outputId": "8de37b2f-6f39-4906-bb48-bda45142d00d"
   },
   "outputs": [],
   "source": [
    "from numpy.ma.core import minimum\n",
    "metadata2 = []\n",
    "must_have_tags = \"solo\" #@param {'type': 'string'}\n",
    "unwated_tags = \"meme, amiya_(guard)_(arknights), amiya_(newsgirl)_(arknights), amiya_(fresh_fastener)_(arknights), amiya_(planter)_(arknights), monochrome, comic, sex, hetero, yuri, 2girls, 3girls, multiple_boys, multiple_girls, 1boy, chibi, 2boys, 3boys, english_text, multiple_views, japanese_text, chinese_text, translation_request, censored\" #@param {'type': 'string'}\n",
    "minimum_score = 9 #@param {'type': 'integer'}\n",
    "include_children = False #@param {'type': 'boolean'}\n",
    "acceptable_file_types = [\"jpeg\", \"jpeg\", \"png\", \"webp\", \"bmp\"]\n",
    "must_have_tags_list = must_have_tags.replace(\" \", \"\").split(\",\")\n",
    "unwated_tags_list = unwated_tags.replace(\" \", \"\").split(\",\")\n",
    "\n",
    "for post in metadata:\n",
    "  wanted = True\n",
    "  if post['is_deleted']:\n",
    "    continue # we won't consider deleted posts\n",
    "  if not post['file_ext'] in acceptable_file_types:\n",
    "    continue # we won't consider non image based sources\n",
    "  if not include_children and post['parent_id']:\n",
    "    continue # reject because we don't want children and this is a child by virtue of having a parent\n",
    "  if post['score'] < minimum_score:\n",
    "    continue; # reject for being under score\n",
    "  for wanted_tag in must_have_tags_list:\n",
    "    if not wanted_tag in post['tag_string']:\n",
    "      wanted = False # reject because the wanted tag is not present\n",
    "      break\n",
    "  for unwanted_tag in unwated_tags_list:\n",
    "    if unwanted_tag in post['tag_string']:\n",
    "      wanted = False # reject for having unwanted tag\n",
    "      break\n",
    "  if wanted:\n",
    "    metadata2.append(post)\n",
    "\n",
    "print(f\"Original metadata contained {len(metadata)} posts. Trimmed down to {len(metadata2)} posts. Removed {len(metadata) - len(metadata2)} posts.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "H9qDsmK9cjGj",
    "outputId": "93b50a10-c60e-43b3-e07e-c9b87e81680c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "scores = [x[\"score\"] for x in metadata2]\n",
    "np_scores = np.asarray(scores)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.boxplot(np_scores)\n",
    "plt.title(\"Score\")\n",
    "percentiles = np.percentile(np_scores, [0, 25, 50, 75, 100]).astype(np.int64)\n",
    "print(f\"lowest score: {percentiles[0]}\")\n",
    "print(f\"25th percentile score: {percentiles[1]}\")\n",
    "print(f\"50th percentile score: {percentiles[2]}\")\n",
    "print(f\"75th percentile score: {percentiles[3]}\")\n",
    "print(f\"highest score: {percentiles[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aV7CsiuFhT50"
   },
   "source": [
    "## Detour\n",
    "What do images at a particular score in our current filtered list look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WhvjAQXDhSSZ",
    "outputId": "635b476f-32ed-44ef-8840-e86093524eba"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "target_score =  9#@param {'type':'integer'}\n",
    "image_limit = 3 #@param {'type': 'integer'}\n",
    "\n",
    "used = 0\n",
    "for post in metadata2:\n",
    "  if post[\"score\"] == target_score:\n",
    "    !wget {post[\"file_url\"]} -O \"example\"\n",
    "    img = cv2.imread(\"example\")\n",
    "    img_cvt=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_cvt)\n",
    "    plt.show()\n",
    "    print(f\"Post {post['id']} with score {post['score']}\")\n",
    "    used+=1\n",
    "    if used >= image_limit:\n",
    "      break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdGyybt9u8BD"
   },
   "source": [
    "## Partitioning our data\n",
    "When training a LoRA we want images that have a broad range of representation of our subject. For example, if we wanted to train a LoRA for a character we would want full body tagged images or we might never learn what kind of shoes they wear. \n",
    "\n",
    "Sometimes certain types of images are a lot rarer than others so we want to break down our potential images into several categories so later we can set appropriate thresholds for determining which images we will keep for each category while maintaining a suitable number of images for training. \n",
    "\n",
    "**categories**: a comma delimited list of space sperated tags.\n",
    "Example: *full_body standing, cowboy_shot*\n",
    "each category will have only posts that have all tags in the category (so a category of only posts with *full_body and standing*)\n",
    "\n",
    "An image will only be in one category, the first category in the list where they meet the condition. So if your categories were *standing, standing full_body*, then all the standing images would be in the first category and the second category of *standing full_body* will have no images because those were also *standing* images.\n",
    "\n",
    "The *remaining* category will be everything else that didn't meet a category criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pPg7Kwmu7rg",
    "outputId": "0dd75cca-4387-43a6-9c9f-41b17cb98fb2"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "categories_dict = defaultdict(list)\n",
    "categories = \"violin, ascot jacket ring\"  #@param {'type': 'string'}\n",
    "category_tags = [x.strip().split(\" \") for x in categories.split(\",\")]\n",
    "print(f\"Creating {len(category_tags) + 1} categories of {category_tags} and remaining\")\n",
    "\n",
    "for category in category_tags: # we set a default ahead of time so the order of dictionary is same as user entry\n",
    "  categories_dict[\" \".join(category)] = []\n",
    "\n",
    "for post in metadata2:\n",
    "  found_matching_category = False\n",
    "  for category in category_tags:\n",
    "    has_all_tags = True\n",
    "    for tag in category:\n",
    "      if tag in post['tag_string']:\n",
    "        continue\n",
    "      else:\n",
    "        has_all_tags = False\n",
    "\n",
    "    if has_all_tags:\n",
    "      categories_dict[\" \".join(category)].append(post)\n",
    "      found_matching_category = True\n",
    "  \n",
    "  if not found_matching_category:\n",
    "    categories_dict[\"remaining\"].append(post)\n",
    "\n",
    "i=1\n",
    "for key in categories_dict.keys():\n",
    "  print(f\"category {i}: {key} has {len(categories_dict[key])} posts\")\n",
    "  i+=1   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SEOmMif7qpG"
   },
   "source": [
    "## Visualize Categories\n",
    "Let's break down the number of posts and the images in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GKEsXMZN3mlO",
    "outputId": "3157980d-a8ce-48d1-fcff-d0a6411e6524"
   },
   "outputs": [],
   "source": [
    "categories_keys = []\n",
    "categories_scores = []\n",
    "for key in categories_dict.keys():\n",
    "  scores = [post['score'] for post in categories_dict[key]]\n",
    "  num_images = len(scores)\n",
    "  np_scores = np.asarray(scores)\n",
    "  percentiles = np.percentile(np_scores, [0, 25, 50, 75, 100]).astype(np.int64)\n",
    "  categories_keys.append(key + f\"\\nimages:{num_images}\" + f\"\\nlowest score:{percentiles[0]}\" + f\"\\n25th percentil score:{percentiles[1]}\" + f\"\\n50th percentil score:{percentiles[2]}\" + f\"\\n75th percentil score:{percentiles[3]}\" + f\"\\nhighest score:{percentiles[4]}\")\n",
    "  categories_scores.append(np_scores)\n",
    "np_categories_scores = np.asarray(categories_scores)\n",
    "plt.figure(figsize=(25, 15))\n",
    "plt.boxplot(np_categories_scores, labels=categories_keys, showfliers=False)\n",
    "plt.title(\"Categories and scores\")\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97ZoatMR2A3S"
   },
   "source": [
    "## Per category score thresholding\n",
    "For each category we will individuall assign a score threshold for what is accepted. While score isn't truly the best measure of how well an image will serve as training data for getting an accurate representation of our subject, we do have a good deal of confidence that higher rated images are drawn better and aesthetics is important for our dataset.\n",
    "\n",
    "**scores_for_each_category**: this is a list of scores for each category where the post must be at or above this score in order to be kept. This should have as many numbers as you had categories in the previous section, including the _remaining_ category. It will be in the order you specified with *remaining* being last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2xB9bkp19vj",
    "outputId": "45d8b48c-6857-43f7-e8b8-f1fa256bb0c8"
   },
   "outputs": [],
   "source": [
    "scores_for_each_category = \"9, 12, 24\" #@param {'type': 'string'}\n",
    "scores_for_each_category_list = [int(x.strip()) for x in scores_for_each_category.split(\",\")]\n",
    "print(\"Thresholding each category with scores:\")\n",
    "i = 0\n",
    "for key in categories_dict.keys():\n",
    "  print(f\"    {key:<30} score: {scores_for_each_category_list[i]} \")\n",
    "  i+=1\n",
    "\n",
    "threshholded_categories_dict = defaultdict(list)\n",
    "i = 0\n",
    "for key in categories_dict.keys():\n",
    "  required_score_for_category = scores_for_each_category_list[i]\n",
    "  for post in categories_dict[key]:\n",
    "    if post['score'] >= required_score_for_category:\n",
    "      threshholded_categories_dict[key].append(post)\n",
    "  i+= 1\n",
    "\n",
    "print(f\"Before thresholding:\")\n",
    "i=1\n",
    "for key in categories_dict.keys():\n",
    "  print(f\"    category {i}: {key} has {len(categories_dict[key])} posts\")\n",
    "  i+=1   \n",
    "# report thresholding results\n",
    "print(f\"After thresholding:\")\n",
    "i=1\n",
    "for key in threshholded_categories_dict.keys():\n",
    "  print(f\"    category {i}: {key} has {len(threshholded_categories_dict[key])} posts\")\n",
    "  i+=1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udJAICenB7_q"
   },
   "source": [
    "## Download data\n",
    "Now we will download all the posts that remain after thresholding.\n",
    "Each post will be downloaded into a directory for the category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkOlaAh6CcQO",
    "outputId": "13f6e575-d64a-4793-fec9-d7c1da44e121"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "directory = \"/content/data/\" #@param {'type': 'string'}\n",
    "prepend_tags = \"amiya_(arknights)\" #@param {'type': 'string'}\n",
    "process_tags_for_training_format = True #@param {'type': 'boolean'}\n",
    "download_images = True #@param {'type': 'boolean'}\n",
    "\n",
    "Path(f\"{directory}\").mkdir(exist_ok=True)\n",
    "\n",
    "metadata_json = json.dumps(metadata)\n",
    "with open(f'{directory}/metadata.json','w') as f:\n",
    "  f.write(metadata_json)\n",
    "\n",
    "for key in threshholded_categories_dict.keys():\n",
    "  Path(f\"{directory}/{key}\").mkdir(exist_ok=True)\n",
    "  for post in threshholded_categories_dict[key]:\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'}\n",
    "    if not \"file_url\" in post:\n",
    "      print(f\"post {post['id']} has no file_url\")\n",
    "      continue # some posts don't have a file_url\n",
    "    file_url = post[\"file_url\"]\n",
    "    file_name = post[\"id\"]\n",
    "    file_extension = post[\"file_ext\"]\n",
    "    tag_string = post[\"tag_string_general\"]\n",
    "\n",
    "    file_path = Path(f'{directory}/{key}')\n",
    "    file_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # Write metadata\n",
    "    p = Path(file_path, f'{file_name}.json')\n",
    "    p.write_text(json.dumps(post))\n",
    "    # Write tags\n",
    "    tags = prepend_tags + \" \" + tag_string\n",
    "    if process_tags_for_training_format:\n",
    "      tags = tags.replace(\" \", \", \").replace(\"_\", \" \")\n",
    "    Path(file_path, f'{file_name}.txt').write_text(tags)\n",
    "\n",
    "    if download_images:\n",
    "      r = requests.get(file_url, stream = True, headers=header)\n",
    "      if r.status_code == 200:\n",
    "          # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "          r.raw.decode_content = True\n",
    "          Path(file_path, f'{file_name}.{file_extension}').write_bytes(r.raw.data)\n",
    "    else:\n",
    "        print('Image Couldn\\'t be retreived,', file_url, post)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhNdmvcPPWZW"
   },
   "source": [
    "# Package up data\n",
    "Zip up the data for download. You can download directly from collab (might be slow) or move the contents to a mounted gdrive or upload to huggingface via git lfs (implement it yourself, this only supports direct download from collab atm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsYvfFGRPPBS",
    "outputId": "3127593d-b6f8-4eba-deb4-fe02be2cf830"
   },
   "outputs": [],
   "source": [
    "directory = \"/content/data/\" #@param {'type': 'string'}\n",
    "zip_file = \"/content/data.zip\" #@param {'type': 'string'}\n",
    "!zip -r {zip_file} {directory}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGSYCOHDl12i"
   },
   "source": [
    "#Upload to hugging face for later consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6r2tse8mPKn"
   },
   "source": [
    "##install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2wt3BC9DmMHk",
    "outputId": "5e902ffe-119a-4cf9-98b9-120bb3d246c9"
   },
   "outputs": [],
   "source": [
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYrw1z9qnApR"
   },
   "source": [
    "##login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574,
     "referenced_widgets": [
      "bc03dc471b8945efbcade9badf97a6fa",
      "bba9cb4afd6b4413bdada3ffc91007b7",
      "07b6c3b5d605408591dc2acd843c3cde",
      "fd9dc0e9bf0844d49f042fd09544b365",
      "d7959b6e345948d6ada85d08f0a001bc",
      "58ed67b48ded4845b37d4e6e1adbe3bb",
      "146f82d184d4483b97af22ede9efde6e",
      "d582079ce56142019037d20228a7cf74",
      "4ede0a79a625439198d0fd5c3ee4cb90",
      "a5f3874e826d4847a02c599c45de9942",
      "bdaca6bf89a44ae59b35dab31c421584",
      "7477d546f6204c558ef0fe72cb488a80",
      "c177d6c2b0a843cb846366229664d899",
      "30b56cd11c354d9f9b501910384dcf63",
      "355e94f9e01548a3a3d6f19917700e69",
      "d787eb0210c24803a6cbad8c89fc87d0",
      "0ee98c597b3646fb9218d13f2692c280"
     ]
    },
    "id": "55ztWDTOl1eb",
    "outputId": "da94dc09-ec92-49f3-c14a-9f63c81fbe2c"
   },
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.notebook_login()\n",
    "huggingface_hub.whoami()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzMQ4iSGm-3n"
   },
   "source": [
    "##upload to hf\n",
    "Creates a hugging face repo if it doesn't exist\n",
    "uploads zip to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "9231cb2c88be481f9f720d992bde845f",
      "883ac90321934a12aae94078ffb4984f",
      "a51cdec74a2248058a76404066e7e830",
      "7eb6aa10685449bab7de4cc0acf7ceea",
      "642aa79ae7114755b469a887db3519e9",
      "9164155cd6e448a8a14a61a2afafd996",
      "e3d205325b3c475bbb871050e9aeef1a",
      "8cd0c878cacc40599a1a944e5765e902",
      "e273892973344184a0da78a68e10af6d",
      "e41375ac83a546bdbb86c108b9998512",
      "5a16dae67d3a497bb6cccba54a32f035",
      "783b543bd7444ca9b963baa4ce774678",
      "bec9b67aba3d480da5709bed990a0c1d",
      "2b79b216d4c64a5c9adf43ab5b374249",
      "4ab6cbf1b00840a7a1688f4bb391675b",
      "8b9bc2a4ad754e769ca85bb0193abfef",
      "8caa6b92f72549cf890ccec301f4845d",
      "97183bd396424ad3923748e9299d3411",
      "0142447d17964146bc09758cffcc137d",
      "de2db788a546415583579c160b94a001",
      "4419bf3d02a74e8783a0272217f71d33",
      "ef5793bdb0bd4ee7ac0ec91cc9fcc79c"
     ]
    },
    "id": "ZWcsSO0Zm9z9",
    "outputId": "ceb4f342-eca4-492c-973d-57cde01be4f7"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import create_repo, upload_file\n",
    "from huggingface_hub.utils import HfHubHTTPError\n",
    "\n",
    "zip_file = \"/content/data.zip\" #@param {'type': 'string'}\n",
    "huggingface_database_repo_name = \"breakcore2/amiya_arknights\" #@param {'type': 'string'} \n",
    "create_new_repro_if_not_exist = True #@param {'type': 'boolean'}\n",
    "make_repro_private = True #@param {'type': 'boolean'}\n",
    "\n",
    "if create_new_repro_if_not_exist:\n",
    "  try:\n",
    "    create_repo(huggingface_database_repo_name, repo_type=\"dataset\", private=make_repro_private)\n",
    "  except HfHubHTTPError:\n",
    "    # there could be other http errors codes but w/e\n",
    "    print(f\"dataset {huggingface_database_repo_name} already exists\")\n",
    "\n",
    "upload_file(\n",
    "    path_or_fileobj=zip_file,\n",
    "    path_in_repo=\"data.zip\",\n",
    "    repo_id=huggingface_database_repo_name,\n",
    "    repo_type=\"dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE3HEiZutqme"
   },
   "source": [
    "# Clean up Data\n",
    "After inspecting the data you have, you may find certain images unwanted from your data set. Here we will delete them, then you can run the zip cell and reupload to hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AK9EeBC1tqLy",
    "outputId": "fc53432d-0d78-47e1-d522-b525e958ee89"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "unwanted_post_ids = \"4015097, 4492858, 4525492, 4953900\" #@param {'type': 'string'}\n",
    "directory = \"/content/data/\" #@param {'type': 'string'}\n",
    "unwanted_post_ids_list = [x for x in unwanted_post_ids.replace(\" \", \"\").split(\",\")]\n",
    "\n",
    "path = Path(directory)\n",
    "for unwanted_post_id in unwanted_post_ids_list:\n",
    "  unwanted_files = list(path.rglob(f'{unwanted_post_id}.*'))\n",
    "  for unwated_file in unwanted_files:\n",
    "    print(f\"deleting {unwated_file}\")\n",
    "    !rm \"{str(unwated_file)}\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
